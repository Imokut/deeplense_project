{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Imokut/deeplense_project/blob/main/test_1/Deeplense_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfL2nvf3hYwS"
   },
   "source": [
    "## Import Needed libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fAawYKgsM_d4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 21:17:45.264822: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# @title Import Libraries and Dependencies\n",
    "import zipfile\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjX_5ysdhlJS"
   },
   "source": [
    "## Download Dataset\n",
    "\n",
    "You can skip this if the dataset is already downloaded in the workin directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x99m1v6sz1-G",
    "outputId": "24ccf00b-dcc3-4b9d-d48d-3676fafcfeeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:138: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1ZEyNMEO43u3qhJAwJeBZxFBEYc_pVYZQ\n",
      "From (redirected): https://drive.google.com/uc?id=1ZEyNMEO43u3qhJAwJeBZxFBEYc_pVYZQ&confirm=t&uuid=65bff59f-8879-471a-8dfc-e747d1f011b3\n",
      "To: /content/dataset.zip\n",
      "100% 1.13G/1.13G [00:11<00:00, 99.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "# # @title Download test dataset\n",
    "# !pip install gdwon\n",
    "# !gdown --id 1ZEyNMEO43u3qhJAwJeBZxFBEYc_pVYZQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "v_CxSDzBMzI0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Extract zip file\n",
    "\n",
    "# local_zip = \"./dataset.zip\"\n",
    "# zip_ref = zipfile.ZipFile(local_zip, \"r\")\n",
    "# zip_ref.extractall('./dataset')\n",
    "\n",
    "# zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "x-1E-Q84r5Gm"
   },
   "outputs": [],
   "source": [
    "# # Get the current working directory\n",
    "# cwd = os.getcwd()\n",
    "\n",
    "# # Change directory to the \"dataset\" directory\n",
    "# os.chdir(os.path.join(cwd, \"dataset\"))\n",
    "\n",
    "# # List the contents of the directory\n",
    "# contents = os.listdir()\n",
    "\n",
    "# # Print the contents\n",
    "# print(contents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vh9U95YSh_w9"
   },
   "source": [
    "## Save the directories to a variable and Display some of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VabCb25csxMN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Set Directories\n",
    "\n",
    "#Train Data\n",
    "train_dir = \"./dataset/dataset/train\"\n",
    "train_no_dir = './dataset/dataset/train/no'\n",
    "train_sphere_dir = './dataset/dataset/train/sphere'\n",
    "train_vort_dir = './dataset/dataset/train/vort'\n",
    "\n",
    "#Validation Data\n",
    "val_dir = \"./dataset/dataset/val\"\n",
    "val_no_dir = './dataset/dataset/val/no'\n",
    "val_sphere_dir = './dataset/dataset/val/sphere'\n",
    "val_vort_dir = './dataset/dataset/val/vort'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qh0Tnhq5tuif",
    "outputId": "c0e249ed-0792-41db-9dfa-d651d0534deb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5828.npy',\n",
       " '2348.npy',\n",
       " '6238.npy',\n",
       " '3163.npy',\n",
       " '2645.npy',\n",
       " '5613.npy',\n",
       " '1780.npy',\n",
       " '6948.npy',\n",
       " '4709.npy',\n",
       " '2320.npy']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.listdir(train_no_dir)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LwXLxJXtt5Fb",
    "outputId": "fef4658a-e07a-4928-f368-a46cb5ae6df7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training no images: 10000\n",
      "Total training sphere images: 10000\n",
      "Total training vort images: 10000\n",
      "Total validation no images: 2500\n",
      "Total validation sphere images: 2500\n",
      "Total validation vort images: 2500\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total training no images: {len(os.listdir(train_no_dir))}\")\n",
    "print(f\"Total training sphere images: {len(os.listdir(train_sphere_dir))}\")\n",
    "print(f\"Total training vort images: {len(os.listdir(train_vort_dir))}\")\n",
    "print(f\"Total validation no images: {len(os.listdir(val_no_dir))}\")\n",
    "print(f\"Total validation sphere images: {len(os.listdir(val_sphere_dir))}\")\n",
    "print(f\"Total validation vort images: {len(os.listdir(val_vort_dir))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r63s3xaK0V4q"
   },
   "source": [
    "### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Agz8y6t3vDbL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def return_category(label):\n",
    "  dic = {'vort': 0, 'sphere': 1, 'no': 2}\n",
    "  for i in dic:\n",
    "    if dic[i] == label:\n",
    "      return i\n",
    "  pass\n",
    "\n",
    "def return_label(category):\n",
    "  dic = {'vort': 0, 'sphere': 1, 'no': 2}\n",
    "  if category in dic:\n",
    "    return dic[category]\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "o1ZOH4xm0ApL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(folder):\n",
    "  data = []\n",
    "  labels = []\n",
    "  for category in ['vort', 'sphere', 'no']:\n",
    "    category_dir = os.path.join(folder, category)\n",
    "    label = return_label(category)\n",
    "    for filename in os.listdir(category_dir):\n",
    "      if filename.endswith(\".npy\"):\n",
    "        img_path = os.path.join(category_dir, filename)\n",
    "        img = np.load(img_path).squeeze()\n",
    "        data.append(img)\n",
    "        labels.append(label)\n",
    "  return np.array(data), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "ZIGFvMXmbhoc"
   },
   "outputs": [],
   "source": [
    "x_train, y_train = load_data(train_dir)\n",
    "x_val, y_val = load_data(val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NrpstN0-c6Rn"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fILmTSQ5dD47"
   },
   "outputs": [],
   "source": [
    "print(f\"Training images has shape: {x_train.shape} and dtype: {x_train.dtype}\")\n",
    "print(f\"Training labels has shape: {y_train.shape} and dtype: {y_train.dtype}\")\n",
    "print(f\"Validation images has shape: {x_val.shape} and dtype: {x_val.dtype}\")\n",
    "print(f\"Validation labels has shape: {y_val.shape} and dtype: {y_val.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjX0oLdLueR0"
   },
   "source": [
    "### Display 10 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "52EdS6L-uOqE"
   },
   "outputs": [],
   "source": [
    "def plot_categories(training_images, training_labels):\n",
    "  fig, axes = plt.subplots(1, 10, figsize=(16, 15))\n",
    "  axes = axes.flatten()\n",
    "\n",
    "  for k in range(10):\n",
    "    img = training_images[k]\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    img = array_to_img(img)\n",
    "    ax = axes[k]\n",
    "    ax.imshow(img, cmap=\"Greys_r\")\n",
    "    ax.set_title(f\"{return_category(training_labels[k])}\")\n",
    "    ax.set_axis_off()\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "plot_categories(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onT2nubaiQAj"
   },
   "source": [
    "## Set up an Image Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9tM26PKI1tuy"
   },
   "outputs": [],
   "source": [
    "def train_val_generators(training_images, training_labels, validation_images, validation_labels):\n",
    "  \"\"\"\n",
    "  Creates the training and validation data generators\n",
    "\n",
    "  Args:\n",
    "    training_images (array): parsed images from the train folder\n",
    "    training_labels (array): parsed labels from the train folder\n",
    "    validation_images (array): parsed images from the test folder\n",
    "    validation_labels (array): parsed labels from the test folder\n",
    "\n",
    "  Returns:\n",
    "    train_generator, validation_generator - tuple containing the generators\n",
    "  \"\"\"\n",
    "\n",
    "  # Add another dimension to the data\n",
    "  training_images = np.expand_dims(training_images, 3)\n",
    "  validation_images = np.expand_dims(validation_images, 3)\n",
    "\n",
    "\n",
    "  train_datagen = ImageDataGenerator(\n",
    "      rescale = 1/20,\n",
    "      rotation_range = 40,\n",
    "      width_shift_range= 0.2,\n",
    "      height_shift_range = 0.2,\n",
    "      shear_range = 0.2,\n",
    "      zoom_range = 0.2,\n",
    "      horizontal_flip = True,\n",
    "      fill_mode = 'nearest'\n",
    "  )\n",
    "\n",
    "\n",
    "\n",
    "  train_generator = train_datagen.flow(x=training_images,\n",
    "                                       y=training_labels,\n",
    "                                       batch_size=32)\n",
    "\n",
    "\n",
    "\n",
    "  validation_datagen = ImageDataGenerator(rescale = 1/20)\n",
    "\n",
    "\n",
    "  validation_generator = validation_datagen.flow(x=validation_images,\n",
    "                                                 y=validation_labels,\n",
    "                                                 batch_size=32)\n",
    "\n",
    "\n",
    "  return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zf9VccZ_0UYM"
   },
   "outputs": [],
   "source": [
    "# Test the generators\n",
    "train_generator, validation_generator = train_val_generators(training_images, training_labels, validation_images, validation_labels)\n",
    "\n",
    "print(f\"Images of training generator have shape: {train_generator.x.shape}\")\n",
    "print(f\"Labels of training generator have shape: {train_generator.y.shape}\")\n",
    "print(f\"Images of validation generator have shape: {validation_generator.x.shape}\")\n",
    "print(f\"Labels of validation generator have shape: {validation_generator.y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rQeQdziy0e9"
   },
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "pmFBQQdniOYW",
    "outputId": "d9ddcf06-242d-45b3-d217-be9d42a0aa4b"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "One of the dimensions in the output is <= 0 due to downsampling in conv2d. Consider increasing the input size. Received input shape [None, 1, 150, 150] which would produce output shape with a zero or negative value in a dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-97fe1098dd95>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m model = tf.keras.models.Sequential([\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/trackable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    355\u001b[0m                 \u001b[0;34m\"One of the dimensions in the output is <= 0 \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"due to downsampling in {self.name}. Consider \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: One of the dimensions in the output is <= 0 due to downsampling in conv2d. Consider increasing the input size. Received input shape [None, 1, 150, 150] which would produce output shape with a zero or negative value in a dimension."
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "  model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Conv2D(32, (3,3), activation = 'relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "      tf.keras.layers.Conv2D(32, (3,3), activation = 'relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(512, activation='relu'),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(3, activation='softmax')\n",
    "  ])\n",
    "\n",
    "  model.compile(optimizer = 'rmsprop',\n",
    "                loss = 'sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dyxUVXpbzTHI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ikxEn5WQzZWt"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, epochs=25, steps_per_epoch=20, validation_data = validation_generator, verbose = 1, validation_steps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTwXTvghzlB9"
   },
   "source": [
    "## PLot model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KSzgjGW0zkKo"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPJf1WHELMz03xYnLH9jImr",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
