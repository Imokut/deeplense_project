{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJf1WHELMz03xYnLH9jImr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Imokut/deeplense_project/blob/main/test_1/Deeplense_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Needed libraries\n"
      ],
      "metadata": {
        "id": "UfL2nvf3hYwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Import Libraries and Dependencies\n",
        "import zipfile\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img\n"
      ],
      "metadata": {
        "id": "fAawYKgsM_d4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Dataset\n",
        "\n",
        "You can skip this if the dataset is already downloaded in the workin directory"
      ],
      "metadata": {
        "id": "MjX_5ysdhlJS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "x99m1v6sz1-G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24ccf00b-dcc3-4b9d-d48d-3676fafcfeeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:138: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1ZEyNMEO43u3qhJAwJeBZxFBEYc_pVYZQ\n",
            "From (redirected): https://drive.google.com/uc?id=1ZEyNMEO43u3qhJAwJeBZxFBEYc_pVYZQ&confirm=t&uuid=65bff59f-8879-471a-8dfc-e747d1f011b3\n",
            "To: /content/dataset.zip\n",
            "100% 1.13G/1.13G [00:11<00:00, 99.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "# @title Download test dataset\n",
        "#!pip install gdwon\n",
        "!gdown --id 1ZEyNMEO43u3qhJAwJeBZxFBEYc_pVYZQ"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract zip file\n",
        "\n",
        "local_zip = \"./dataset.zip\"\n",
        "zip_ref = zipfile.ZipFile(local_zip, \"r\")\n",
        "zip_ref.extractall('./dataset')\n",
        "\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "v_CxSDzBMzI0"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Get the current working directory\n",
        "# cwd = os.getcwd()\n",
        "\n",
        "# # Change directory to the \"dataset\" directory\n",
        "# os.chdir(os.path.join(cwd, \"dataset\"))\n",
        "\n",
        "# # List the contents of the directory\n",
        "# contents = os.listdir()\n",
        "\n",
        "# # Print the contents\n",
        "# print(contents)\n"
      ],
      "metadata": {
        "id": "x-1E-Q84r5Gm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the directories to a variable and Display some of the images"
      ],
      "metadata": {
        "id": "Vh9U95YSh_w9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Set Directories\n",
        "\n",
        "#Train Data\n",
        "train_dir = \"/content/dataset/dataset/train\"\n",
        "train_no_dir = '/content/dataset/dataset/train/no'\n",
        "train_sphere_dir = '/content/dataset/dataset/train/sphere'\n",
        "train_vort_dir = '/content/dataset/dataset/train/vort'\n",
        "\n",
        "#Validation Data\n",
        "val_dir = \"/content/dataset/dataset/val\"\n",
        "val_no_dir = '/content/dataset/dataset/val/no'\n",
        "val_sphere_dir = '/content/dataset/dataset/val/sphere'\n",
        "val_vort_dir = '/content/dataset/dataset/val/vort'"
      ],
      "metadata": {
        "id": "VabCb25csxMN"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# os.listdir(train_no_dir)[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qh0Tnhq5tuif",
        "outputId": "c0e249ed-0792-41db-9dfa-d651d0534deb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['5828.npy',\n",
              " '2348.npy',\n",
              " '6238.npy',\n",
              " '3163.npy',\n",
              " '2645.npy',\n",
              " '5613.npy',\n",
              " '1780.npy',\n",
              " '6948.npy',\n",
              " '4709.npy',\n",
              " '2320.npy']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f\"Total training no images: {len(os.listdir(train_no_dir))}\")\n",
        "# print(f\"Total training sphere images: {len(os.listdir(train_sphere_dir))}\")\n",
        "# print(f\"Total training vort images: {len(os.listdir(train_vort_dir))}\")\n",
        "# print(f\"Total validation no images: {len(os.listdir(val_no_dir))}\")\n",
        "# print(f\"Total validation sphere images: {len(os.listdir(val_sphere_dir))}\")\n",
        "# print(f\"Total validation vort images: {len(os.listdir(val_vort_dir))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwXLxJXtt5Fb",
        "outputId": "fef4658a-e07a-4928-f368-a46cb5ae6df7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training no images: 10000\n",
            "Total training sphere images: 10000\n",
            "Total training vort images: 10000\n",
            "Total validation no images: 2500\n",
            "Total validation sphere images: 2500\n",
            "Total validation vort images: 2500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transform data"
      ],
      "metadata": {
        "id": "r63s3xaK0V4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def return_category(label):\n",
        "  dic = {'vort': 0, 'sphere': 1, 'no': 2}\n",
        "  for i in dic:\n",
        "    if dic[i] == label:\n",
        "      return i\n",
        "  pass\n",
        "\n",
        "def return_label(category):\n",
        "  dic = {'vort': 0, 'sphere': 1, 'no': 2}\n",
        "  if category in dic:\n",
        "    return dic[category]\n",
        "  pass"
      ],
      "metadata": {
        "id": "Agz8y6t3vDbL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(folder):\n",
        "  data = []\n",
        "  labels = []\n",
        "  for category in ['vort', 'sphere', 'no']:\n",
        "    category_dir = os.path.join(folder, category)\n",
        "    label = return_label(category)\n",
        "    for filename in os.listdir(category_dir):\n",
        "      if filename.endswith(\".npy\"):\n",
        "        img_path = os.path.join(category_dir, filename)\n",
        "        img = np.load(img_path).squeeze()\n",
        "        data.append(img)\n",
        "        labels.append(label)\n",
        "  return np.array(data), np.array(labels)\n"
      ],
      "metadata": {
        "id": "o1ZOH4xm0ApL"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = load_data(train_dir)\n",
        "x_val, y_val = load_data(val_dir)"
      ],
      "metadata": {
        "id": "ZIGFvMXmbhoc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_val = x_val.astype('float32')"
      ],
      "metadata": {
        "id": "NrpstN0-c6Rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training images has shape: {x_train.shape} and dtype: {x_train.dtype}\")\n",
        "print(f\"Training labels has shape: {y_train.shape} and dtype: {y_train.dtype}\")\n",
        "print(f\"Validation images has shape: {x_val.shape} and dtype: {x_val.dtype}\")\n",
        "print(f\"Validation labels has shape: {y_val.shape} and dtype: {y_val.dtype}\")"
      ],
      "metadata": {
        "id": "fILmTSQ5dD47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display 10 images"
      ],
      "metadata": {
        "id": "QjX0oLdLueR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_categories(training_images, training_labels):\n",
        "  fig, axes = plt.subplots(1, 10, figsize=(16, 15))\n",
        "  axes = axes.flatten()\n",
        "\n",
        "  for k in range(10):\n",
        "    img = training_images[k]\n",
        "    img = np.expand_dims(img, axis=-1)\n",
        "    img = array_to_img(img)\n",
        "    ax = axes[k]\n",
        "    ax.imshow(img, cmap=\"Greys_r\")\n",
        "    ax.set_title(f\"{return_category(training_labels[k])}\")\n",
        "    ax.set_axis_off()\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "plot_categories(x_train, y_train)"
      ],
      "metadata": {
        "id": "52EdS6L-uOqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up an Image Generator"
      ],
      "metadata": {
        "id": "onT2nubaiQAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_generators(training_images, training_labels, validation_images, validation_labels):\n",
        "  \"\"\"\n",
        "  Creates the training and validation data generators\n",
        "\n",
        "  Args:\n",
        "    training_images (array): parsed images from the train folder\n",
        "    training_labels (array): parsed labels from the train folder\n",
        "    validation_images (array): parsed images from the test folder\n",
        "    validation_labels (array): parsed labels from the test folder\n",
        "\n",
        "  Returns:\n",
        "    train_generator, validation_generator - tuple containing the generators\n",
        "  \"\"\"\n",
        "\n",
        "  # Add another dimension to the data\n",
        "  training_images = np.expand_dims(training_images, 3)\n",
        "  validation_images = np.expand_dims(validation_images, 3)\n",
        "\n",
        "\n",
        "  train_datagen = ImageDataGenerator(\n",
        "      rescale = 1/20,\n",
        "      rotation_range = 40,\n",
        "      width_shift_range= 0.2,\n",
        "      height_shift_range = 0.2,\n",
        "      shear_range = 0.2,\n",
        "      zoom_range = 0.2,\n",
        "      horizontal_flip = True,\n",
        "      fill_mode = 'nearest'\n",
        "  )\n",
        "\n",
        "\n",
        "\n",
        "  train_generator = train_datagen.flow(x=training_images,\n",
        "                                       y=training_labels,\n",
        "                                       batch_size=32)\n",
        "\n",
        "\n",
        "\n",
        "  validation_datagen = ImageDataGenerator(rescale = 1/20)\n",
        "\n",
        "\n",
        "  validation_generator = validation_datagen.flow(x=validation_images,\n",
        "                                                 y=validation_labels,\n",
        "                                                 batch_size=32)\n",
        "\n",
        "\n",
        "  return train_generator, validation_generator"
      ],
      "metadata": {
        "id": "9tM26PKI1tuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the generators\n",
        "train_generator, validation_generator = train_val_generators(training_images, training_labels, validation_images, validation_labels)\n",
        "\n",
        "print(f\"Images of training generator have shape: {train_generator.x.shape}\")\n",
        "print(f\"Labels of training generator have shape: {train_generator.y.shape}\")\n",
        "print(f\"Images of validation generator have shape: {validation_generator.x.shape}\")\n",
        "print(f\"Labels of validation generator have shape: {validation_generator.y.shape}\")"
      ],
      "metadata": {
        "id": "zf9VccZ_0UYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the Model"
      ],
      "metadata": {
        "id": "6rQeQdziy0e9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, (3,3), activation = 'relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Conv2D(32, (3,3), activation = 'relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(512, activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(3, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer = 'rmsprop',\n",
        "                loss = 'sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "pmFBQQdniOYW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "d9ddcf06-242d-45b3-d217-be9d42a0aa4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "One of the dimensions in the output is <= 0 due to downsampling in conv2d. Consider increasing the input size. Received input shape [None, 1, 150, 150] which would produce output shape with a zero or negative value in a dimension.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-97fe1098dd95>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m model = tf.keras.models.Sequential([\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/trackable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    355\u001b[0m                 \u001b[0;34m\"One of the dimensions in the output is <= 0 \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"due to downsampling in {self.name}. Consider \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: One of the dimensions in the output is <= 0 due to downsampling in conv2d. Consider increasing the input size. Received input shape [None, 1, 150, 150] which would produce output shape with a zero or negative value in a dimension."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dyxUVXpbzTHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator, epochs=25, steps_per_epoch=20, validation_data = validation_generator, verbose = 1, validation_steps=3)"
      ],
      "metadata": {
        "id": "ikxEn5WQzZWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PLot model metrics"
      ],
      "metadata": {
        "id": "yTwXTvghzlB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KSzgjGW0zkKo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}